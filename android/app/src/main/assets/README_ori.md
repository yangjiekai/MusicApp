![Animation](/assets/deepdrum.gif)

In this interactive demo, I have used Google Magenta's [DrumsRNN](https://github.com/tensorflow/magenta/tree/master/magenta/models/drums_rnn) to generate continuous drum patterns based on your input pattern inside a seed limit and Google Magenta's [ImprovRNN](https://github.com/tensorflow/magenta/tree/master/magenta/models/improv_rnn) to generate arpeggio patterns based on your input notes conditioned on a chord. Based on your seed inputs, the deep neural networks (LSTMs) will generate drum and arpeggio patterns live in your browser!

[Demo](https://gogul09.github.io/software/deep-drum)

[Blog post](https://gogul09.github.io/software/creating-intelligent-music-applications-in-the-browser)

[Google Magenta Demos](https://magenta.tensorflow.org/demos/community/)

[YouTube video instructions](https://www.youtube.com/watch?v=sjo6UlQONLc)